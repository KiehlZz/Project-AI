{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: k-nearest-neighbor (KNN) from scratch [0.81339]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data preparation**\n",
    "\n",
    "First lets import the data and generate one set to process all data at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['set'], test['set'] = 'train', 'test'\n",
    "combined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values\n",
    "\n",
    "First step is to fill missing values and drop columns we will not be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age             263\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "set               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not be using Embarked and Cabin for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = combined.drop(['Cabin', 'Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one Fare price is missing. fill it with the median of his Pclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass = combined.loc[combined.Fare.isnull(), 'Pclass'].values[0]\n",
    "median_fare = combined.loc[combined.Pclass== pclass, 'Fare'].median()\n",
    "combined.loc[combined.Fare.isnull(), 'Fare'] = median_fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing ages\n",
    "\n",
    "To fill in the missing ages, we can do something more clever then just take the overal median age. The names contain titles of which some are linked to their age. Master is a younger boy (in general). Lets take the median of each age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess',\n",
       "       'Jonkheer', 'Dona'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select everything before the . as title\n",
    "combined['Title'] = combined['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "combined['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Rev', 'Dr'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_reduction = {'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', \n",
    "                   'Master': 'Master', 'Don': 'Mr', 'Rev': 'Rev',\n",
    "                   'Dr': 'Dr', 'Mme': 'Miss', 'Ms': 'Miss',\n",
    "                   'Major': 'Mr', 'Lady': 'Mrs', 'Sir': 'Mr',\n",
    "                   'Mlle': 'Miss', 'Col': 'Mr', 'Capt': 'Mr',\n",
    "                   'Countess': 'Mrs','Jonkheer': 'Mr',\n",
    "                   'Dona': 'Mrs'}\n",
    "combined['Title'] = combined['Title'].map(title_reduction)\n",
    "combined['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr 49.0\n",
      "Master 4.0\n",
      "Miss 22.0\n",
      "Mr 30.0\n",
      "Mrs 36.0\n",
      "Rev 41.5\n"
     ]
    }
   ],
   "source": [
    "for title, age in combined.groupby('Title')['Age'].median().items():\n",
    "    print(title, age)\n",
    "    combined.loc[(combined['Title']==title) & (combined['Age'].isnull()), 'Age'] = age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age               0\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              0\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "set               0\n",
       "Title             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create additional features**\n",
    "\n",
    "An interesting theory I saw here on Kaggle is that there are groups of people, who would help each other. This might affect the survivability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_family_members_survived(dataset, label='family_survival'):\n",
    "    \"\"\"\n",
    "    Check if other family members survived\n",
    "      -> 0 other did not survive\n",
    "      -> 1 at least one other family member survived\n",
    "      -> 0.5 unknown if other members survived or person was alone\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : DataFrame\n",
    "      The sub-dataframe containing the family\n",
    "    \"\"\"\n",
    "    ds = dataset.copy()\n",
    "    if len(dataset) == 1:\n",
    "        ds[label] = 0.5\n",
    "        return ds\n",
    "    result = []\n",
    "    for ix, row in dataset.iterrows():\n",
    "        survived_fraction = dataset.drop(ix)['Survived'].mean()\n",
    "        if np.isnan(survived_fraction):\n",
    "            result.append(0.5)\n",
    "        elif survived_fraction == 0:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    ds[label] = result\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_8924\\2887954477.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  combined = combined.groupby(['surname', 'Fare']).apply(other_family_members_survived).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "combined['surname'] = combined['Name'].apply(lambda x: x.split(\",\")[0])\n",
    "combined = combined.groupby(['surname', 'Fare']).apply(other_family_members_survived).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data on families can also be extracted from Tickets. Same ticket orders have the same ticket number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_8924\\2452194539.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  combined = combined.groupby(['Ticket']).apply(lambda x: other_family_members_survived(x, label='family_survival_ticket')).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "combined = combined.groupby(['Ticket']).apply(lambda x: other_family_members_survived(x, label='family_survival_ticket')).reset_index(drop=True)\n",
    "combined.loc[combined['family_survival'] == 0.5, 'family_survival'] = combined.loc[combined['family_survival'] == 0.5, 'family_survival_ticket']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
