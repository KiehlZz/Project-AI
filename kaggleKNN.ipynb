{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: k-nearest-neighbor (KNN) from scratch [0.81339]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Data preparation**\n",
    "\n",
    "First lets import the data and generate one set to process all data at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['set'], test['set'] = 'train', 'test'\n",
    "combined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values\n",
    "\n",
    "First step is to fill missing values and drop columns we will not be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age             263\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "set               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not be using Embarked and Cabin for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = combined.drop(['Cabin', 'Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one Fare price is missing. fill it with the median of his Pclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass = combined.loc[combined.Fare.isnull(), 'Pclass'].values[0]\n",
    "median_fare = combined.loc[combined.Pclass== pclass, 'Fare'].median()\n",
    "combined.loc[combined.Fare.isnull(), 'Fare'] = median_fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing ages\n",
    "\n",
    "To fill in the missing ages, we can do something more clever then just take the overal median age. The names contain titles of which some are linked to their age. Master is a younger boy (in general). Lets take the median of each age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess',\n",
       "       'Jonkheer', 'Dona'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select everything before the . as title\n",
    "combined['Title'] = combined['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "combined['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Rev', 'Dr'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_reduction = {'Mr': 'Mr', 'Mrs': 'Mrs', 'Miss': 'Miss', \n",
    "                   'Master': 'Master', 'Don': 'Mr', 'Rev': 'Rev',\n",
    "                   'Dr': 'Dr', 'Mme': 'Miss', 'Ms': 'Miss',\n",
    "                   'Major': 'Mr', 'Lady': 'Mrs', 'Sir': 'Mr',\n",
    "                   'Mlle': 'Miss', 'Col': 'Mr', 'Capt': 'Mr',\n",
    "                   'Countess': 'Mrs','Jonkheer': 'Mr',\n",
    "                   'Dona': 'Mrs'}\n",
    "combined['Title'] = combined['Title'].map(title_reduction)\n",
    "combined['Title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr 49.0\n",
      "Master 4.0\n",
      "Miss 22.0\n",
      "Mr 30.0\n",
      "Mrs 36.0\n",
      "Rev 41.5\n"
     ]
    }
   ],
   "source": [
    "for title, age in combined.groupby('Title')['Age'].median().items():\n",
    "    print(title, age)\n",
    "    combined.loc[(combined['Title']==title) & (combined['Age'].isnull()), 'Age'] = age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Survived        418\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age               0\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              0\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "set               0\n",
       "Title             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create additional features**\n",
    "\n",
    "An interesting theory I saw here on Kaggle is that there are groups of people, who would help each other. This might affect the survivability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_family_members_survived(dataset, label='family_survival'):\n",
    "    \"\"\"\n",
    "    Check if other family members survived\n",
    "      -> 0 other did not survive\n",
    "      -> 1 at least one other family member survived\n",
    "      -> 0.5 unknown if other members survived or person was alone\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : DataFrame\n",
    "      The sub-dataframe containing the family\n",
    "    \"\"\"\n",
    "    ds = dataset.copy()\n",
    "    if len(dataset) == 1:\n",
    "        ds[label] = 0.5\n",
    "        return ds\n",
    "    result = []\n",
    "    for ix, row in dataset.iterrows():\n",
    "        survived_fraction = dataset.drop(ix)['Survived'].mean()\n",
    "        if np.isnan(survived_fraction):\n",
    "            result.append(0.5)\n",
    "        elif survived_fraction == 0:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            result.append(1)\n",
    "    ds[label] = result\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_14164\\2887954477.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  combined = combined.groupby(['surname', 'Fare']).apply(other_family_members_survived).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "combined['surname'] = combined['Name'].apply(lambda x: x.split(\",\")[0])\n",
    "combined = combined.groupby(['surname', 'Fare']).apply(other_family_members_survived).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data on families can also be extracted from Tickets. Same ticket orders have the same ticket number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_14164\\2452194539.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  combined = combined.groupby(['Ticket']).apply(lambda x: other_family_members_survived(x, label='family_survival_ticket')).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "combined = combined.groupby(['Ticket']).apply(lambda x: other_family_members_survived(x, label='family_survival_ticket')).reset_index(drop=True)\n",
    "combined.loc[combined['family_survival'] == 0.5, 'family_survival'] = combined.loc[combined['family_survival'] == 0.5, 'family_survival_ticket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get family size from Parch and Sibsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['family_size'] = combined['Parch'] + combined['SibSp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN needs numerical features therefore, we will convert them to numbers. In a general sense, binary categorical data can work. For larger categorical groups, it only makes sense when the numerical values itself have meaning. For example, for class levels, the difference between first class and third class actually mean something. On the other hand, if we would convert Embarked to a number, there is no meaning in the difference between embarked 1 and embarked 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['Sex'] = LabelEncoder().fit_transform(combined['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First bin the Fare and Age. The groups are choosen arbitrarily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.loc[:, 'Age'] = pd.qcut(combined['Age'], 4, labels=False)\n",
    "combined.loc[:, 'Fare'] = pd.qcut(combined['Fare'], 5, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only coluns we will use and scale them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['Pclass', 'Sex', 'Age', 'Fare', 'family_size', 'family_survival']\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(combined[selected])\n",
    "combined[selected] = scaler.transform(combined[selected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_parquet('titanic_family_survivabillity.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the sets back to train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combined.loc[combined['set'] == 'train'].drop('set', axis=1).reset_index(drop=True)\n",
    "test = combined.loc[combined['set'] == 'test'].drop(['set', 'Survived'], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Algorithm**\n",
    "\n",
    "KNN works by finding, as the name suggests, the nearest neighbor. It assumes that classes share similar properties. To compare to points, we have to see them as vectors. Each feature adds to a dimension. Would we only have a single feature it would be the numeric distance between the two points. With two or more features, we need to do something smarter. To create a single number to express the similarity (or distance) we need to agegrate all the features (or dimensions). One way is to use the Euclidean distance, which is the root of the sum of squared distances between all features. There are many other ways to agegrate the feature distances, all with their strengths and weaknesses. For this example, we will use the Euclidean distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclidean_distance(vector1, vector2):\n",
    "    return np.sqrt(np.sum((vector1 - vector2)**2))\n",
    "\n",
    "# test function\n",
    "vec1 = np.array([3, 0])\n",
    "vec2 = np.array([0, 4])\n",
    "\n",
    "# this is the 3:4:5 triangle and therefore, it should return 5 (Long live Pythagoras)\n",
    "euclidean_distance(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our distance function we will now find the closest match in our dataset, when providing a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  Survived\n",
       "1  2  2         1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A first implementation\n",
    "def get_nearest_neighbor(vector, dataset, number_of_neighbors=1, ignore_cols=['Survived']):\n",
    "    distances = []\n",
    "    for ix, row in dataset.loc[:, ~dataset.columns.isin(ignore_cols)].iterrows():\n",
    "        distance = euclidean_distance(row, vector)\n",
    "        distances.append((distance, ix))\n",
    "    indices = [x[1] for x in sorted(distances, key=lambda x: x[0])]\n",
    "    neighbors = dataset.loc[indices[:number_of_neighbors]]\n",
    "    return neighbors\n",
    "\n",
    "# Another implementation using Pandas\n",
    "def get_nearest_neighbor(vector, dataset, number_of_vectors=1, ignore_cols=['Survived'], not_count_duplicates=False):\n",
    "    ds = dataset.copy()\n",
    "    ds['distance'] = ds.loc[:, ~ds.columns.isin(ignore_cols)].apply(\n",
    "        lambda x: euclidean_distance(x, vector), axis=1)\n",
    "    if not_count_duplicates:\n",
    "        distances = sorted(ds.distance.unique())[:number_of_vectors]\n",
    "        return ds.loc[ds.distance <= max(distances)].drop('distance', axis=1)\n",
    "    return ds.sort_values('distance', ascending=True).head(number_of_vectors).drop('distance', axis=1)\n",
    "        \n",
    "# test function\n",
    "dataset = pd.DataFrame([\n",
    "    {'a': 1, 'b': 1, 'Survived': 1},\n",
    "    {'a': 2, 'b': 2, 'Survived': 1},\n",
    "    {'a': 3, 'b': 3, 'Survived': 0},\n",
    "    {'a': 4, 'b': 4, 'Survived': 0},\n",
    "    {'a': 5, 'b': 5, 'Survived': 0},\n",
    "])\n",
    "vector = pd.Series({'a': 2.5, 'b': 2.5})\n",
    "\n",
    "# should be (2,2) and (3,3) (if keeping track of duplicates)\n",
    "get_nearest_neighbor(vector, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function to list the nearest neighbors, we need to select the most dominant class of those neighbors to select as our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def predict(vector, dataset, number_of_neighbors=1, y='Survived'):\n",
    "    neighbors = get_nearest_neighbor(vector, dataset, number_of_neighbors)\n",
    "    return round(neighbors[y].mean())\n",
    "\n",
    "# test function\n",
    "print(predict(vector, dataset))\n",
    "print(predict(pd.Series({'a': 4.5, 'b': 4.5}), dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Test algorithm on Titanic dataset**\n",
    "\n",
    "To test, we select on row from the set and use KNN to find the best candidate. Of course, we will remove that row from the dataset, or we would find a distance of zero as the identical row is in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "Accuracy: 0.835016835016835\n"
     ]
    }
   ],
   "source": [
    "def predict_dataset(dataset, number_of_neighbors=1):\n",
    "    ds = dataset.copy()\n",
    "    def predict_row(vector, dataset):\n",
    "        subset = dataset.loc[~(dataset.index==vector.name)]\n",
    "        if vector.name % 100 == 0:\n",
    "            print(vector.name)\n",
    "        return int(predict(vector, subset, number_of_neighbors))\n",
    "\n",
    "    ds['predicted'] = ds.loc[:, ds.columns.isin(selected)].apply(\n",
    "        lambda x: predict_row(x, ds), axis=1)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "ds = predict_dataset(train, number_of_neighbors=10)\n",
    "\n",
    "print('Accuracy:', sum(ds['Survived'] == ds['predicted']) / len(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a accuracy of **83.5%** on the training set. Lets now make our test set predictions.\n",
    "\n",
    "**5. create prediction for testset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_testset(test_dataset, train_dataset, number_of_neighbors=1):\n",
    "    ds = test_dataset.copy()\n",
    "    select = selected + ['Survived']\n",
    "    \n",
    "    def predict_row(vector, dataset):\n",
    "        if vector.name % 100 == 0:\n",
    "            print(vector.name)\n",
    "        return int(predict(vector, dataset[select], number_of_neighbors))\n",
    "\n",
    "    ds['Survived'] = ds.loc[:, ds.columns.isin(selected)].apply(\n",
    "        lambda x: predict_row(x, train_dataset), axis=1)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "final_test = predict_testset(test, train, number_of_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_test[['PassengerId', 'Survived']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0           1227         0\n",
       "1           1050         0\n",
       "2           1128         0\n",
       "3           1083         0\n",
       "4           1158         0\n",
       "..           ...       ...\n",
       "413         1114         1\n",
       "414          925         0\n",
       "415         1136         0\n",
       "416         1059         0\n",
       "417          906         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_411",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
